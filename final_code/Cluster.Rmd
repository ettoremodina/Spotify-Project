---
title: "Cluster"
author: "Alessandra Pescina"
date: "2024-01-21"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
seed=2024
```

Loading data

```{r}
numeric_data<-readRDS("data_final/data_numeric_cleaned.RData")

#scale in (0,1) year and duration
min_max_normalize <- function(x) {
  return((x - min(x)) / (max(x) - min(x)))
}

pca_data <- numeric_data[,-13]
pca_data$duration<-  min_max_normalize(numeric_data$duration)
pca_data$year<-  min_max_normalize(numeric_data$year)
```


## PCA

In order to fit clusters of songs, we decided to exploit PCA to extract latent information from the numerical variables.
```{r}
n <- dim(pca_data)[1]
p <- dim(pca_data)[2]

# checking variability: if there are some variables with a very larger variance, 
# they could driven the analysis of Principal Components:
boxplot(pca_data, las = 2, col = 'gold')

# performing PCA:
pc.data <- princomp(pca_data, scores=T)
summary(pc.data)
load.data <- pc.data$loadings

cumsum(pc.data$sd^2)/sum(pc.data$sd^2)

varmax <- max(var(pca_data[,1:dim(pca_data)[2]]))
varmax_pc <- max(pc.data$sd)
layout(matrix(c(2,3,1,3),2,byrow=T))
plot(pc.data, las=2, main='Principal components', ylim=c(0,varmax_pc^2))
barplot(sapply(pca_data,sd)^2, las=2, main='Original Variables', ylim=c(0,varmax),
        ylab='Variances')
plot(cumsum(pc.data$sd^2)/sum(pc.data$sd^2), type='b', axes=F, 
     xlab='number of components', ylab='contribution to the total variance', ylim=c(0,1))
abline(h=1, col='blue')
abline(h=0.8, lty=2, col='blue')
box()
axis(2,at=0:10/10,labels=0:10/10)
axis(1,at=1:ncol(pca_data),labels=1:ncol(pca_data),las=2)

#considero le prime 6 pca (82% della varianza spiegata, non troppo soddisfaciente ma ci provo)
```

k number of chosen princpal component 
```{r}
k <- 6
par(mfrow = c(3,2))
for(i in 1:k) barplot(load.data[,i], ylim = c(-1, 1), main = paste('PC', i))
pca_red_data <- data.frame(pc.data$scores[,1:k])
```


## Cluster of songs 

euclidean, 6 pc, ward.D2
```{r}
library(StatMatch)
n<-dim(pca_red_data)[1]
p<-dim(pca_red_data)[2]
distance <- 'canberra' # manhattan, canberra
linkages <- c('single', 'average', 'complete', 'ward.D2')

# distance matrix:
data.dist_e <- dist(pca_red_data, method=distance)
#data.dist<-mahalanobis.dist(numeric_red)
#temp<-dist(data.dist)
# plot:
#image(1:n,1:n, as.matrix(data.dist), main=paste('metrics: ', distance), asp=1, xlab='', ylab='')


# perform hierarchical clustering:
#data.s <- hclust(data.dist, method=linkages[1])
#data.a <- hclust(data.dist, method=linkages[2])
#data.c <- hclust(data.dist, method=linkages[3])
#data.w <- hclust(data.dist, method=linkages[4])

# perform hierarchical clustering maha:
data.s <- hclust(data.dist_e, method=linkages[1])
data.a <- hclust(data.dist_e, method=linkages[2])
data.c <- hclust(data.dist_e, method=linkages[3])
data.w <- hclust(data.dist_e, method=linkages[4])

# plot dendograms:
x11()   #quartz() if form mac
par(mfrow=c(2,2))

plot(data.s, main=paste(distance, ' - ', linkages[1]), hang=-0.1, xlab='', labels=F, cex=0.6, sub='')
plot(data.a, main=paste(distance, ' - ', linkages[2]), hang=-0.1, xlab='', labels=F, cex=0.6, sub='')
plot(data.c, main=paste(distance, ' - ', linkages[3]), hang=-0.1, xlab='', labels=F, cex=0.6, sub='')
plot(data.w, main=paste(distance, ' - ', linkages[4]), hang=-0.1, xlab='', labels=F, cex=0.6, sub='')
```

```{r}
#cut dendogram:
k=4
data.hc<-data.w
clusters <- cutree(data.hc, k=k)


#Dimension of the Clusters
table(clusters)
```


```{r}

numeric_data$cluster<-clusters
#saveRDS(numeric_data,"data_final/numeric_clusters.RData")
```

## Assign people to clusters

```{r}
library(dplyr)


# Count the distribution of songs in each cluster for each playlist
playlist_cluster_counts <- numeric_data %>%
  group_by(id, cluster) %>%
  summarise(count = n())

# Display the result
print(playlist_cluster_counts)

library(tidyr)
cluster_df <- playlist_cluster_counts %>%
  pivot_wider(names_from = cluster, values_from = count, values_fill = 0) %>%
  select(id, everything())
```


```{r}
cluster_df_centered<-cluster_df[,-1]
cluster_df_centered$final<-apply(cluster_df_centered, 1, function(row) which.max(row))
table(cluster_df_centered$final)
```

## Classify people 

```{r}
survey_data<-readRDS("data_final/survey_reduced.RData")
survey_data$cluster<-cluster_df_centered$final
survey_data<-survey_data[,-c(8,13,15)]
survey_data$cluster<-as.factor(survey_data$cluster)
survey_data$cluster <- make.names(survey_data$cluster)
survey_data$campo.studi<-ifelse(is.na(survey_data$campo.studi), "others", survey_data$campo.studi)
```

## Decision Tree (trivial)
```{r}
library(rpart)
library(caret)
fit<-rpart(as.factor(cluster) ~. , data=survey_data)
summary(fit)
residuals(fit)

x11() #quartz()
plot(fit)

text(fit, use.n=T)

predictions <- predict(fit, survey_data, type = "class")
conf_matrix <- confusionMatrix(predictions, as.factor(survey_data$cluster))
print(conf_matrix)
```
##Random Forest

LOOCV to tune the parameter assigning the number of features to select at each tree
```{r}
library(randomForest)
library(caret)
set.seed(2024)

param_grid <- expand.grid(
  mtry = seq(4, ncol(survey_data) - 1, by = 1)  # Adjust the range as needed
)

# Define the control parameters for the cross-validation
ctrl <- trainControl(
  method = "LOOCV",  # Use leave-one-out cross-validation
  search = "grid",
  summaryFunction = defaultSummary,
  classProbs = TRUE,
  verboseIter = TRUE
)

# Fit the Random Forest model with cross-validation
rf_model <- train(
  cluster ~ .,
  data = survey_data,
  method = "rf",  # Use Random Forest
  trControl = ctrl,
  tuneGrid = param_grid
)

# Print the best model's parameters
print(rf_model$bestTune)

# Access the best Random Forest model
best_rf_model <- rf_model$finalModel
```
Fit the rf with the best hyperparameters

```{r}

fit_RF<-randomForest(as.factor(cluster) ~ ., data = survey_data, mtry=4, ntree=5000, replace=T)
fit_RF

```

Features mostly used by the rf
```{r}
importance_features <- importance(fit_RF)
importance_features
sort(importance_features, decreasing=T) 
varImpPlot(fit_RF)

#saveRDS(survey_data,"data_final/survey_cluster.RData")
```

