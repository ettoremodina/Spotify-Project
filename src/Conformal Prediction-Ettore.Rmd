---
title: "R Notebook"
output: html_notebook
---
```{r}
library(hexbin)
library(ggplot2)
library(roahd)
library(spatstat.geom)
library(dplyr) 
library(ggplot2)
library(knitr)
library(broom)
library(tidyr)
library(progress)
library(pbapply)
pboptions(type='none')
library(dbscan)
library(gridExtra)
library(rgl)
library(DepthProc)
library(hexbin)
library(aplpack)
library(robustbase)

```


```{r}
data_numeric_cleaned = readRDS("../data/data_numeric_cleaned2.RData")
survey_data = readRDS("../data/Surveycleaned.RData")
test<-survey_data$campo.studi!="STEM (Science, Technology, Engineering, Mathematics)"         
survey_data$campo.studi<-ifelse(test,"Others","STEM (Science, Technology, Engineering, Mathematics)")
survey_data$campo.studi[is.na(survey_data$campo.studi)] = "missing"
###########
test<-survey_data$stato!="Italia"         
survey_data$stato<-ifelse(test,"Others","Italia")
survey_data$stato[is.na(survey_data$stato)] = "missing"
###########
test<-survey_data$libri!="0"         
survey_data$libri<-ifelse(test,"1+","0")
survey_data$libri[is.na(survey_data$libri)] = "missing"
##########
test<-survey_data$estero!="No"         
survey_data$estero<-ifelse(test,"Si","No")
survey_data$estero[is.na(survey_data$estero)] = "missing"
##########
colnames(survey_data)[1] = "age"

test<-survey_data$age < 22.5         
survey_data$age<-ifelse(test,"Under22.5","Over22.5")
survey_data$age[is.na(survey_data$age)] = "missing"
######### TO DO
# test<-survey_data$genere!="No"         
# survey_data$genere<-ifelse(test,"Si","No")
# survey_data$genere[is.na(survey_data$genere)] = "missing"
######### 
test<-survey_data$concerti>5         
survey_data$concerti<-ifelse(test,"more than 5","less than 5")
######### 
survey_data$regione[is.na(survey_data$regione)] = "missing"
######### TO DO


# new to create only 2 levels


survey_data$abitanti.citta <- factor(survey_data$abitanti.citta, levels = c(levels(survey_data$abitanti.citta), "meno di 100.000 abitanti","Più di 100.000 abitanti"))

survey_data$abitanti.citta[survey_data$abitanti.citta=="Meno di 1000 abitanti"] =as.factor("meno di 100.000 abitanti")


survey_data$abitanti.citta[survey_data$abitanti.citta=="Tra 1.000 e 10.000 abitanti"] = "meno di 100.000 abitanti"
survey_data$abitanti.citta[survey_data$abitanti.citta=="Tra 10.000 e 100.000"] = "meno di 100.000 abitanti"
survey_data$abitanti.citta[survey_data$abitanti.citta=="Tra 100.000 e 500.000 abitanti"] = "Più di 100.000 abitanti"
survey_data$abitanti.citta[survey_data$abitanti.citta=="Più di 500 000 abitanti"] = "Più di 100.000 abitanti"

# Rimuovi livelli vuoti
survey_data$abitanti.citta <- droplevels(survey_data$abitanti.citta)

###

survey_data$lavoro <- factor(survey_data$lavoro, levels = c(levels(survey_data$lavoro), "si"))

survey_data$lavoro[survey_data$lavoro=="Part time" ] = "si"
survey_data$lavoro[survey_data$lavoro=="Full time" ] = "si"
survey_data$lavoro <- droplevels(survey_data$lavoro)



####


survey_data$importanza.musica[survey_data$importanza.musica=="tanto" ] = "molto"
survey_data$importanza.musica[survey_data$importanza.musica=="abbastanza" ] = "poco"
survey_data$importanza.musica <- droplevels(survey_data$importanza.musica)


###
survey_data$campo.studi[survey_data$campo.studi=="missing" ] = "Others"
#survey_data$campo.studi <- droplevels(survey_data$campo.studi)
```


# combine the data

```{r}
combined_data <- merge(data_numeric_cleaned, survey_data, by.x = "id", by.y = "id")
head(combined_data)
dim(combined_data)
```



# NC measure
```{r}
# | Discrepancy-based |
NC = function(z_aug, i){
  #abs(z_aug[i] - mean(z_aug[-i]))
  abs(z_aug[i] - median(z_aug[-i]))  # more robust
  #abs(z_aug[i] - 18)                  # a deterministic predictor
  #abs(z_aug[i] - random.number)       # a fully random predictor
}
```

# main function
```{r}
conformal_univariate_interval <- function(x, plotting = FALSE){
  alpha = 0.05
  x_grid  = seq(min(x)-0.25*diff(range(x)), max(x)+0.25*diff(range(x)), length.out=100)
  p_value = numeric(length(x_grid))


  for(k in 1:length(x_grid)){
    x_aug  = c(x, x_grid[k])
    scores = numeric(length(x_aug))
    for(i in 1:length(scores)){
      scores[i] = NC(x_aug, i)
    }
    p_value[k] = sum(scores>=scores[length(x_aug)])/(length(x_aug))
  }

  # Prediction Interval
  PI_grid = x_grid[which(p_value>=alpha)]
      # cut if exceed [0,1], the prediction is still valid at alpha percent
  PI      = c(max(min(PI_grid),0),min(max(PI_grid),1) )
  
  # KNN 
  # PI <- x_grid[as.logical(c(0,abs(diff(p_value>alpha))))]
  
  
  if(plotting){
    # Plot of the p-values
    plot(x_grid, p_value, type='l', ylim=c(0,1))
    abline(h=c(0,1))
    abline(h=alpha, col='red')
    points(x, numeric(length(x)), pch=3)
    abline(v=PI, col='red')
    points(PI_grid, numeric(length(PI_grid)), pch=16, col='red')
    
    
    hist(x, col='lightblue')
    abline(v=PI,col='blue') # Conformal prediction interval
    
    legend("topright", legend="Conformal", col="blue",
           lty=1, cex=0.8)
  }
  return(PI)

}
```

# Music and Survey covariates
```{r}
music_vars = colnames(data_numeric_cleaned)
music_vars = music_vars[!(music_vars %in% c("id","year","duration"))] # exclude year and duration
survey_covs = colnames(survey_data)
survey_covs = survey_covs[!(survey_covs %in% c("genere","id"))]
```

# Example
```{r}
univariate_data_filtered = combined_data[combined_data[,"sesso"] == "Maschio", "popularity"]
conformal_univariate_interval(univariate_data_filtered)
```




# For loop for every possible combination- 400 tests
```{r}
alpha = 0.15
#list_intervals = list()
for(s in survey_covs){
  groups_survey = levels(as.factor(combined_data[,s]))
  for ( m in music_vars ){
    for( g in groups_survey){
      
      name_for_list = paste0(s,": ",g,", VAR: ",m)

      
      # jump tests that have already been done
      if(!(name_for_list%in%names(list_intervals))){
        print(name_for_list)
        univariate_data_filtered = combined_data[combined_data[,s] == g, m]
        list_intervals[[name_for_list]] = conformal_univariate_interval(univariate_data_filtered)

      }
      
   
    }
  }
}

```




# Saving data
```{r}
#saveRDS(list_intervals,"../conformal_intervals_byGroups.RData")
list_intervals = readRDS("../conformal_intervals_byGroups.RData")
```

# Relevant variables from other tests
(permutational and band depth)
```{r}
# dunctional band depth
survey_covs_chosen = c("sesso","campo.studi","stato","lavoro","importanza.musica",
                       "come.ascolti.musica","politica","regione","abitanti.citta",
                       "educazione")
music_vars_chosen = c("popularity","acousticness","liveness")
music_vars_chosen = c("popularity","acousticness","danceability","energy","instrumentalness","liveness","loudness","tempo","valence")
```


# Exploring CI
```{r}
plot_CI <- function(temp_list_CI,title){
  g = length(temp_list_CI)
  plot(c(1,g),range(c(0,1)), pch='',
     ylab='Conformal prediction interval', main=title)
  for(i in 1:g) {
    lines(c(i,i), c(temp_list_CI[[i]][1],temp_list_CI[[i]][2]), col='grey55');
    points(i, temp_list_CI[[i]][1], col=rainbow(g)[i], pch=16);
    points(i, temp_list_CI[[i]][2], col=rainbow(g)[i], pch=16);
  }
}

```



```{r}
for(s in survey_covs){
  groups_survey = levels(as.factor(combined_data[,s]))
  for ( m in music_vars){
    temp_list_CI = list()
    count = 1
    for( g in groups_survey){
      
      name_for_list = paste0(s,": ",g,", VAR: ",m)
      
      temp_list_CI[[count]] = list_intervals[[name_for_list]]
      count = count + 1
      title = paste0(s," ",", VAR: ",m)
    
    }
    plot_CI(temp_list_CI,title)
    
  }
}
```
```{r}
Intersection_Over_Union <- function(list){
  lower = c()
  upper = c()
  for(i in 1:length(list)){
    lower = c(lower,list[[i]][1])
    upper = c(upper,list[[i]][2])
  }
  union = max(upper)-min(lower)
  intersection = min(upper) - max(lower)
  return(intersection/union)
}
```


```{r}
IoU_list = list()
for(s in survey_covs){
  groups_survey = levels(as.factor(combined_data[,s]))
  for ( m in music_vars){
    temp_list_CI = list()
    for( g in groups_survey){
      
      name_for_list = paste0(s,": ",g,", VAR: ",m)
      temp_list_CI[[g]] = list_intervals[[name_for_list]]
    }
    
    name = paste0(s," ",", VAR: ",m)
    IoU_list[[name]] = Intersection_Over_Union(temp_list_CI)

  }
}
```
```{r}
soglia = 0.6
for ( i in 1:length(IoU_list)){
  if(IoU_list[[i]]<soglia){
    print(IoU_list[i])
  }
}
```
```{r}
plot(df_unique[,"loudness"],df_unique[,"instrumentalness"],pch = 16, xlab = "loudness",ylab = "instrumentalness")
```

```{r}
IoU_list = list()
for(s in survey_covs){
  groups_survey = combined_data[,s]
    plot(combined_data[,"loudness"],combined_data[,"instrumentalness"],pch = 16, xlab = "loudness",ylab = "instrumentalness",main = s,col =factor(groups_survey) )
    

}
```
# Best 2 groups finder

##
```{r}
condition_1 = combined_data$importanza.musica==levels(combined_data$importanza.musica)[4]
condition_2 = combined_data$politica==levels(combined_data$politica)[2]
conditions <- list(condition_1, condition_2)
# Combine conditions using Reduce with the '&' operator
filter_survey <- Reduce(`&`, conditions)

# Apply the combined filter to the data
filtered_data <- combined_data[filter_survey,]


condition_1 = combined_data$importanza.musica==levels(combined_data$importanza.musica)[2]
condition_2 = combined_data$politica==levels(combined_data$politica)[1]
conditions <- list(condition_1, condition_2)
# Combine conditions using Reduce with the '&' operator
filter_survey <- Reduce(`&`, conditions)

# Apply the combined filter to the data
filtered_data_2 <- combined_data[filter_survey,]





VAL = compute_metric(filtered_data,filtered_data_2)
```
```{r}
compute_number_rows <- function(data_group1,data_group2){
  return(1/dim(data_group1)[1]+1/dim(data_group2)[1])
}
```
```{r}
compute_metric <- function(data_group1,data_group2){
  sum_metric_over_musical_covariates <- 0
  for ( m in music_vars ){
    conf_group1 = conformal_univariate_interval(data_group1[,m])      
    conf_group2 = conformal_univariate_interval(data_group2[,m])
    # cut if exceed [0,1], the prediction is still valid at alpha percent
    conf_group1[1]=max(conf_group1[1],0)
    conf_group2[1]=max(conf_group2[1],0)
    conf_group1[2]=min(conf_group1[2],1)
    conf_group2[2]=min(conf_group2[2],1)
    
    union = max(conf_group1[2],conf_group2[2])-min(conf_group1[1],conf_group2[1])
    intersection = min(conf_group1[2],conf_group2[2]) - max(conf_group1[1],conf_group2[1])

    sum_metric_over_musical_covariates =  sum_metric_over_musical_covariates + intersection/union
  }
  print(paste0("final metric: ",sum_metric_over_musical_covariates))
  return(sum_metric_over_musical_covariates)
}




```

```{r}
check_numerosity <- function(dat1,dat2){
  test = (length(unique(dat1$id))>2 && length(unique(dat2$id))>2)
  return(test)
}
```


```{r}
permutation_levels <- function(survey_covs)  {
  conditions_group_1 <- list()
  conditions_group_2 <- list()
  composition_group_1 <- list()
  composition_group_2 <- list()
  metric_list <- list()

  m_count = 2
  metric_list[[1]] = 100
  num_levels = length(survey_covs)
  for(s in 1:num_levels){
  #for(s in 1:3){
    levels_s = levels(as.factor(combined_data[,survey_covs[s]]))
    print(survey_covs[s])
    
    if(s!=1){ # per la prima iterazione non serve controllare entrambe
      # level 1-2
      condition = combined_data[,survey_covs[s]]==levels_s[1]
      conditions_group_1[[s]] <- condition
      composition_group_1[[s]] <- paste0(survey_covs[s], "level: ",levels_s[1])
      filter_survey <- Reduce(`&`, conditions_group_1)
      data1 = combined_data[filter_survey,]
    
      condition = combined_data[,survey_covs[s]]==levels_s[2]
      conditions_group_2[[s]] <- condition
      composition_group_2[[s]] <- paste0(survey_covs[s], "level: ",levels_s[2])
      filter_survey <- Reduce(`&`, conditions_group_2)
      data2 = combined_data[filter_survey,]
      
      if(check_numerosity(data1,data2)){
        metric = compute_metric(data1,data2)
      }
      else{
        metric = 100
      }
      
      
    }else{
      metric = 100
    }

    
    
    # level 2-1
    condition = combined_data[,survey_covs[s]]==levels_s[2]
    conditions_group_1[[s]] <- condition
    composition_group_1[[s]] <- paste0(survey_covs[s], " level: ",levels_s[2])
    filter_survey <- Reduce(`&`, conditions_group_1)
    data1 = combined_data[filter_survey,]
  
    condition = combined_data[,survey_covs[s]]==levels_s[1]
    conditions_group_2[[s]] <- condition
    composition_group_2[[s]] <- paste0(survey_covs[s], " level: ",levels_s[1])
    filter_survey <- Reduce(`&`, conditions_group_2)
    data2 = combined_data[filter_survey,]

    
    if(check_numerosity(data1,data2)){
      metric_2 = compute_metric(data1,data2)
    }else{
      metric_2 = 100
    }

    metric_list[[m_count]] = metric_2
    
    if(metric<metric_2){
      condition = combined_data[,survey_covs[s]]==levels_s[1]
      conditions_group_1[[s]] <- condition
      composition_group_1[[s]] <- paste0(survey_covs[s], "level: ",levels_s[1])
      
      condition = combined_data[,survey_covs[s]]==levels_s[2]
      conditions_group_2[[s]] <- condition
      composition_group_2[[s]] <- paste0(survey_covs[s], "level: ",levels_s[2])
      
      metric_list[[m_count]] = metric
    }
    
    
    # if this level doesn't produce an increase in the metric we discard it and pass to the next
    if(metric_list[[m_count-1]]< metric_list[[m_count]]){
      conditions_group_1 <- conditions_group_1[-s]
      conditions_group_2 <- conditions_group_2[-s]
      composition_group_1 <- composition_group_1[-s]
      composition_group_2 <- composition_group_2[-s]

    }else{
      m_count = m_count + 1
    }

  }
  

  
  
  return(list(cond1 = conditions_group_1,
              cond2 = conditions_group_2,
              comp1 = composition_group_1,
              comp2 = composition_group_2,
              metrics = metric_list))
}

```

```{r}
music_vars = colnames(data_numeric_cleaned)
music_vars = music_vars[!(music_vars %in% c("id","year","duration","speechness"))] # exclude year and duration
survey_covs = colnames(survey_data)
survey_covs = survey_covs[!(survey_covs %in% c("genere","id","educazione","concerti","come.ascolti.musica","regione"))]


music_vars = c("popularity","acousticness","instrumentalness","liveness")

for ( i in survey_covs){
  print(levels(as.factor(survey_data[,i])))
  print("################")
}
```
```{r}
lis = list(1,2,3,4)
lis2 = lis[-4]
lis2[[4]]
```


```{r}
music_vars = c("popularity"     ,  "acousticness")
metric_list_permutation = list()
survey_covs_permutations <- list()
num_levels = length(survey_covs)

survey_covs_permutations[[1]] <- survey_covs
metric_list_permutation[[1]] <- permutation_levels(survey_covs)
for(i in 11:20){# permutations of levels
  print(paste0("permutation number: ",i))
  survey_covs_permutations[[i]] <- sample(survey_covs)
  metric_list_permutation[[i]] <- permutation_levels(sample(survey_covs))
  
}
saveRDS(metric_list_permutation,"../best2groups.RData")
```



```{r}
data1 = combined_data[combined_data$estero== levels(as.factor(combined_data$estero))[1] #no
                    & combined_data$campo.studi== levels(as.factor(combined_data$campo.studi))[1] #STEM
                    & combined_data$age== levels(as.factor(combined_data$age))[1] #OVER 22
                        ,]



data2 = combined_data[combined_data$estero== levels(as.factor(combined_data$estero))[2] #no
                    & combined_data$campo.studi== levels(as.factor(combined_data$campo.studi))[2] #STEM
                    & combined_data$age== levels(as.factor(combined_data$age))[2] #UNDER 22
                        ,]


length(unique(data1$id))

length(unique(data2$id))

#compute_metric(data1,data2)

conformal_univariate_interval(data1[,"popularity"],TRUE)
conformal_univariate_interval(data1[,"acousticness"],TRUE)
conformal_univariate_interval(data2[,"popularity"],TRUE)
conformal_univariate_interval(data2[,"acousticness"],TRUE)
```


```{r}
vector_of_min = c()
for(i in 1:length(metric_list_permutation)){
  vector_of_min = c( vector_of_min,(min(as.numeric(metric_list_permutation[[i]]$metrics))))
}
#10
#11
metric_list_permutation[[11]]
```

# Multivariate

# **3.** MULTIVARIATE 2

```{r}
data_predict = univariate_data_filtered = combined_data[combined_data[,"sesso"] == "Maschio", c("popularity","acousticness")]

n_grid = 20
grid_factor = 0.25
n = nrow(data_predict)
range_x = range(data_predict[, 1])[2] - range(data_predict[, 1])[1]
range_y = range(data_predict[, 2])[2] - range(data_predict[, 2])[1]
test_grid_x = seq(
  min(data_predict[, 1]) - grid_factor * range_x,
  max(data_predict[, 1]) + grid_factor * range_x,
  length.out = n_grid
  )
test_grid_y = seq(
  min(data_predict[, 2]) - grid_factor * range_y,
  max(data_predict[, 2]) + grid_factor * range_y,
  length.out = n_grid
  )

xy_surface = expand.grid(test_grid_x, test_grid_y)
colnames(xy_surface) = colnames(data_predict)

wrapper_multi_conf = function(test_point) {
  newdata = rbind(test_point, data_predict)
  
  newmedian = depthMedian(newdata, depth_params = list(method = 'Tukey'))
  depth_surface_vec = rowSums(t(t(newdata) - newmedian) ^2) 
  
  sum(depth_surface_vec[-1] >= depth_surface_vec[1]) / (n + 1)
}


pval_surf = pbapply(xy_surface, 1, wrapper_multi_conf)
data_plot = cbind(pval_surf, xy_surface)
p_set = xy_surface[pval_surf > alpha, ]
poly_points = p_set[chull(p_set), ]


ggplot() +
  geom_tile(data = data_plot, aes(popularity, acousticness, fill = pval_surf)) +## change
  geom_point(data = data.frame(data_predict), aes(popularity, acousticness)) +## change
  geom_polygon(
  data = poly_points,
  aes(popularity, acousticness),## change
  color = 'red',
  size = 1,
  alpha = 0.01
  )


```


